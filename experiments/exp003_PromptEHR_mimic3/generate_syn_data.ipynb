{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb700f0c",
   "metadata": {},
   "source": [
    "### PromptEHR合成数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42e5571e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiehuang3/Desktop/synthetic-experiments/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/jiehuang3/Desktop/synthetic-experiments/.venv/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:725: FutureWarning: The class `PretrainedBartModel` has been depreciated, please use `BartPreTrainedModel` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from promptehr import load_synthetic_data\n",
    "\n",
    "data = load_synthetic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d583a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# medical codes词汇对照表\n",
    "voc = data['voc']\n",
    "\n",
    "def decode_visit(visit, voc):\n",
    "    diag_ids, prod_ids, med_ids = visit\n",
    "    diag_codes = [voc['diag'].idx2word[i] for i in diag_ids]\n",
    "    prod_codes = [voc['prod'].idx2word[i] for i in prod_ids]\n",
    "    med_codes  = [voc['med'].idx2word[i] for i in med_ids]\n",
    "    return {\n",
    "        \"diagnoses\": diag_codes,\n",
    "        \"procedures\": prod_codes,\n",
    "        \"medications\": med_codes\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47179d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 5, 7, 41, 313, 1],\n",
       " [0, 1, 82],\n",
       " [2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 51, 19, 26]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient = 0\n",
    "visit = data['visit'][patient][0]  # 第一次就诊\n",
    "visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "723e76c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients = data['visit']\n",
    "len(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86bc992c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均每个患者就诊次数：2.516\n"
     ]
    }
   ],
   "source": [
    "# 平均每个患者就诊次数：2.516\n",
    "sum_length = 0\n",
    "for patient in data['visit']:\n",
    "    sum_length += len(patient)\n",
    "print(\"平均每个患者就诊次数：\" + str(sum_length / len(data['visit'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a2aa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visit 1: {'diagnoses': ['4239', '5119', '78551', '4589', '7220', '2724', 'E8788', 'V4501', '5119'], 'procedures': ['3731', '8872', '3491'], 'medications': ['A02B', 'B05C', 'A12A', 'A12C', 'C01C', 'A07A', 'A10A', 'N01A', 'C07A', 'C03C', 'A12B', 'N07A', 'A03F', 'A02A', 'C10A']}\n",
      "Visit 2: {'diagnoses': ['4239', '5119', 'V1259', '53081'], 'procedures': ['8872', '3961'], 'medications': ['N02B', 'A02B', 'A06A', 'A12C', 'C01C', 'A04A', 'C07A', 'C03C', 'A12B', 'C02D', 'R01A', 'C01E', 'B01A', 'N05C']}\n"
     ]
    }
   ],
   "source": [
    "# 给每个患者解码，每个visit三种codes\n",
    "def decode_patient(patient_id, data):\n",
    "    visits = []\n",
    "    for v in data['visit'][patient_id]:\n",
    "        visits.append(decode_visit(v, data['voc']))\n",
    "    return visits\n",
    "\n",
    "decoded_patient0 = decode_patient(0, data)\n",
    "for i, v in enumerate(decoded_patient0):\n",
    "    print(f\"Visit {i+1}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3459e9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'DataTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download pretrained PromptEHR model, save to ./simulation/pretrained_promptEHR.\n",
      "Load pretrained PromptEHR model from ./simulation/pretrained_promptEHR\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "DataTokenizer has no attribute total_vocab_size",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# init model\u001b[39;00m\n\u001b[32m      6\u001b[39m model = PromptEHR()\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# load input data\u001b[39;00m\n\u001b[32m     10\u001b[39m demo = load_synthetic_data(n_sample=\u001b[32m1000\u001b[39m) \u001b[38;5;66;03m# we have 10,000 samples in total\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/synthetic-experiments/.venv/lib/python3.11/site-packages/promptehr/promptehr.py:359\u001b[39m, in \u001b[36mPromptEHR.from_pretrained\u001b[39m\u001b[34m(self, input_dir)\u001b[39m\n\u001b[32m    356\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mDownload pretrained PromptEHR model, save to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    358\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mLoad pretrained PromptEHR model from\u001b[39m\u001b[33m'\u001b[39m, input_dir)\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/synthetic-experiments/.venv/lib/python3.11/site-packages/promptehr/promptehr.py:298\u001b[39m, in \u001b[36mPromptEHR.load_model\u001b[39m\u001b[34m(self, checkpoint)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;28mself\u001b[39m._load_tokenizer(data_tokenizer_file, model_tokenizer_file)\n\u001b[32m    297\u001b[39m \u001b[38;5;66;03m# load configuration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m \u001b[38;5;28mself\u001b[39m.configuration = \u001b[43mEHRBartConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_num_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mn_num_feature\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_cardinalities\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcat_cardinalities\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[38;5;28mself\u001b[39m.configuration.from_pretrained(checkpoint)\n\u001b[32m    301\u001b[39m \u001b[38;5;66;03m# build model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/synthetic-experiments/.venv/lib/python3.11/site-packages/promptehr/modeling_config.py:24\u001b[39m, in \u001b[36mEHRBartConfig\u001b[39m\u001b[34m(data_tokenizer, model_tokenizer, **kwargs)\u001b[39m\n\u001b[32m     22\u001b[39m bart_config = BartConfig.from_pretrained(\u001b[33m'\u001b[39m\u001b[33mfacebook/bart-base\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     23\u001b[39m kwargs.update(model_tokenizer.get_num_tokens)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m kwargs[\u001b[33m'\u001b[39m\u001b[33mdata_tokenizer_num_vocab\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_tokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33md_prompt_hidden\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m     26\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33md_prompt_hidden\u001b[39m\u001b[33m'\u001b[39m] = \u001b[32m128\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/synthetic-experiments/.venv/lib/python3.11/site-packages/transformers/tokenization_utils.py:502\u001b[39m, in \u001b[36mPreTrainedTokenizer.__len__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    499\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    500\u001b[39m \u001b[33;03m    Size of the full vocabulary with the added tokens.\u001b[39;00m\n\u001b[32m    501\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m502\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtotal_vocab_size\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/synthetic-experiments/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1099\u001b[39m, in \u001b[36mSpecialTokensMixin.__getattr__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1096\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.convert_tokens_to_ids(attr_as_tokens) \u001b[38;5;28;01mif\u001b[39;00m attr_as_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1098\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1099\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1100\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattr__\u001b[39m(key)\n",
      "\u001b[31mAttributeError\u001b[39m: DataTokenizer has no attribute total_vocab_size"
     ]
    }
   ],
   "source": [
    "from promptehr import SequencePatient\n",
    "from promptehr import load_synthetic_data\n",
    "from promptehr import PromptEHR\n",
    "\n",
    "# init model\n",
    "model = PromptEHR()\n",
    "model.from_pretrained()\n",
    "\n",
    "# load input data\n",
    "demo = load_synthetic_data(n_sample=1000) # we have 10,000 samples in total\n",
    "\n",
    "# build the standard input data for train or test PromptEHR models\n",
    "seqdata = SequencePatient(data={'v':demo['visit'], 'y':demo['y'], 'x':demo['feature'],},\n",
    "    metadata={\n",
    "        'visit':{'mode':'dense'},\n",
    "        'label':{'mode':'tensor'}, \n",
    "        'voc':demo['voc'],\n",
    "        'max_visit':20,\n",
    "        }\n",
    "    )\n",
    "# you can try to fit on this data by\n",
    "# model.fit(seqdata)\n",
    "\n",
    "# start generate\n",
    "# n: the target total number of samples to generate\n",
    "# n_per_sample: based on each sample, how many fake samples will be generated\n",
    "# the output will have the same format of `SequencePatient`\n",
    "fake_data = model.predict(seqdata, n=1000, n_per_sample=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0d06e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b94e9628",
   "metadata": {},
   "source": [
    "### LangGraph环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af4e682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 安装相关的包\n",
    "pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python langgraph langgraph-prebuilt langchain_ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19fe04fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables and set up auto-reload\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "715908de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942801d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME             ID              SIZE      MODIFIED     \n",
      "qwen3:14b        7d7da67570e2    9.3 GB    3 months ago    \n",
      "llama3:latest    365c0bd3c000    4.7 GB    5 months ago    \n"
     ]
    }
   ],
   "source": [
    "# 查看ollama中下载的模型\n",
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d219f294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# 使用不同的模型来对话\n",
    "gpt4o = ChatOpenAI(model=\"gpt-4o\", temperature=0.1)\n",
    "llama = ChatOllama(model=\"llama3\", temperature=0.1)\n",
    "qwen = ChatOllama(model=\"qwen3:14b\", temperature=0.1)\n",
    "\n",
    "msg = HumanMessage(content=\"Hello, how are you?\")\n",
    "\n",
    "response = gpt4o.invoke([msg])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5872834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \"5119\" -> \"511.9\" -> \"Unspecified pleural effusion\"\n",
      "2. \"V1259\" -> \"V12.59\" -> \"Personal history of other diseases of the circulatory system\"\n",
      "3. \"78551\" -> \"785.51\" -> \"Cardiogenic shock\"\n"
     ]
    }
   ],
   "source": [
    "diagnoses_translator = \"\"\"\n",
    "    You are a ICD-9 diagnosis code translator.\n",
    "    You will be given a list of ICD-9-CM diagnosis codes, and you need to translate them into a list of natural language descriptions.\n",
    "    Here are some examples of the mapping between ICD-9-CM and natural language descriptions:\n",
    "    \"4239\" -> \"423.9\" -> \"Pericardial disease\"\n",
    "    \"E8788\" -> \"E878.8\" -> \"Other specified surgical operations and procedures causing abnormal patient reaction or later complication without misadventure at time of operation\"\n",
    "    \"V4501\" -> \"V45.01\" -> \"Cardiac pacemaker in situ\"\n",
    "    Now, start the translation with high accuracy and efficiency.\n",
    "\"\"\"\n",
    "\n",
    "diag_result = gpt4o.invoke([SystemMessage(content=diagnoses_translator), HumanMessage(content=\"5119, V1259, 78551\")])\n",
    "print(diag_result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80035afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- \"88.72\" -> \"Diagnostic ultrasound of heart\"\n",
      "- \"39.61\" -> \"Extracorporeal circulation auxiliary to open heart surgery\"\n"
     ]
    }
   ],
   "source": [
    "procedures_translator = \"\"\"\n",
    "    You are a ICD-9-CM procedure code translator.\n",
    "    You will be given a list of ICD-9-CM procedure codes, and you need to translate them into a list of natural language descriptions.\n",
    "    Here are some examples of the mapping between ICD-9-CM procedure codes and natural language descriptions:\n",
    "    \"3731\" -> \"37.31\" -> \"Pericardiectomy\"\n",
    "    \"3491\" -> \"34.91\" -> \"Thoracentesis\"\n",
    "    Now, start the translation with high accuracy and efficiency.\n",
    "\"\"\"\n",
    "\n",
    "proc_result = gpt4o.invoke([SystemMessage(content=procedures_translator), HumanMessage(content=\"8872, 3961\")])\n",
    "print(proc_result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34b66c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- \"A06A\" -> \"Drugs for constipation\"\n",
      "- \"C07A\" -> \"Beta blocking agents\"\n",
      "- \"R01A\" -> \"Decongestants and other nasal preparations for topical use\"\n",
      "- \"N05C\" -> \"Hypnotics and sedatives\"\n"
     ]
    }
   ],
   "source": [
    "medications_translator = \"\"\"\n",
    "    You are a medication code (ATC code) translator.\n",
    "    You will be given a list of medication codes, and you need to translate them into a list of natural language descriptions.\n",
    "    Here are some examples of the mapping between medication codes and natural language descriptions:\n",
    "    \"N02B\" -> \"Other analgesics and antipyretics\"\n",
    "    \"A02B\" -> \"Drugs for peptic ulcer and gastro-oesophageal reflux disease (gord)\"\n",
    "    Now, start the translation with high accuracy and efficiency.\n",
    "\"\"\"\n",
    "\n",
    "med_result = gpt4o.invoke([SystemMessage(content=medications_translator), HumanMessage(content=\"A06A, C07A, R01A, N05C\")])\n",
    "print(med_result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae85ecd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
